# âœ… å…¥åº«è»Šç®¡ç†ã‚¢ãƒ—ãƒªï¼šCSVå–ã‚Šè¾¼ã¿ï¼‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ§‹æƒ³

# ã‚¹ãƒ†ãƒƒãƒ—å…¨ä½“ã®æµã‚Œ
# 1. CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–ã‚Šè¾¼ã‚€
# 2. Vehicleã«æ–°è¦ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚ã‚Šï¼‰
# 3. è»Šå + å‹å¼ã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
# 4. Manufacturerã«è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚ã‚Šï¼‰
# 5. Vehicle.manufacturer_id ã«å¤–éƒ¨ã‚­ãƒ¼ã¨ã—ã¦ç´ä»˜ã‘
# 6. ScrapedInfo ã«å±¥æ­´ã¨ã—ã¦ä¿å­˜ï¼ˆä»»æ„ï¼‰

# --- Flaskãƒ«ãƒ¼ãƒˆã§ã®CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†ä¾‹ ---
# ãƒ•ã‚¡ã‚¤ãƒ«: app/routes.py ã«è¿½åŠ ã™ã‚‹

import time
import csv
import re
import unicodedata
import pandas as pd
from flask import Blueprint, request, jsonify, render_template, redirect, url_for
from sqlalchemy import and_
from app import db
from app.models import Vehicle, Manufacturer, ScrapedInfo
from scraper.scrape_maker import scrape_manufacturer
from datetime import date

bp = Blueprint('routes', __name__)

@bp.route('/import_csv', methods=['POST'])
def import_csv():
    if request.method == 'GET':
        return render_template("import_csv.html")
    
    print("\nâœ… /import_csv ã«åˆ°é”")
    file = request.files.get('file')
    if not file:
        return jsonify({'error': 'CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™'}), 400

    df = pd.read_csv(file, encoding='cp932')

    # âœ… äº‹å‰ã«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ¸ˆã¿IDã‚’é™¤å¤–
    done_ids = db.session.query(Vehicle.internal_code).join(ScrapedInfo).filter(
        ScrapedInfo.manufacturer_name.notin_(["ä»®ãƒ¡ãƒ¼ã‚«ãƒ¼", "ä¸æ˜"])
    ).all()
    done_ids = [code[0] for code in done_ids]
    df = df[~df["è‡ªç¤¾ç®¡ç†ç•ªå·"].isin(done_ids)]
    print(f"ğŸ§¹ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ¸ˆã¿ã® {len(done_ids)} ä»¶ã‚’é™¤å¤–ã—ã¾ã—ãŸ â†’ å‡¦ç†å¯¾è±¡: {len(df)} ä»¶")

    added = 0
    fail_count = 0
    success_count = 0
    fail_ids = []
    processed = 0
    batch_size = 50
    sleep_seconds = 4  # âœ… å®‰å…¨æ€§å‘ä¸Šã®ãŸã‚3ã€œ5ç§’ã«èª¿æ•´

    for row in df.itertuples():
        print(f"\nğŸš— å‡¦ç†ä¸­: {row.è‡ªç¤¾ç®¡ç†ç•ªå·}")
        # âœ… å‹å¼ãŒNaNã‚„ç©ºæ–‡å­—ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if pd.isna(row.èªå®šå‹å¼) or str(row.èªå®šå‹å¼).strip() == "":
            print(f"âš ï¸ å‹å¼ãŒç©ºã¾ãŸã¯NaNã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {row.è‡ªç¤¾ç®¡ç†ç•ªå·}")
            continue

        processed += 1
        if processed > 0 and processed % batch_size == 0:
            print(f"â¸ {batch_size}ä»¶å‡¦ç†ã”ã¨ã«ä¼‘æ†©ä¸­...")
            time.sleep(10)

        vehicle = Vehicle.query.filter_by(internal_code=row.è‡ªç¤¾ç®¡ç†ç•ªå·).first()
        if not vehicle:
            vehicle = Vehicle(
                car_name=row.è»Šå,
                model_code=row.èªå®šå‹å¼,
                year=row.å¹´å¼,
                internal_code=row.è‡ªç¤¾ç®¡ç†ç•ªå·
            )
            db.session.add(vehicle)
            print(f"ğŸ“ Vehicle è¿½åŠ : {row.è‡ªç¤¾ç®¡ç†ç•ªå·}")
        else:
            print(f"ğŸ“¦ Vehicle æ—¢ã«å­˜åœ¨: {row.è‡ªç¤¾ç®¡ç†ç•ªå·}")

        scraped = ScrapedInfo.query.filter_by(vehicle_id=vehicle.id).first()
        # âœ… ã™ã§ã«ä»®ãƒ¡ãƒ¼ã‚«ãƒ¼ä»¥å¤–ãŒç™»éŒ²ã•ã‚Œã¦ã„ãŸã‚‰ã‚¹ã‚­ãƒƒãƒ—
        if scraped and scraped.manufacturer_name not in ["ä»®ãƒ¡ãƒ¼ã‚«ãƒ¼", "ä¸æ˜"]:
            print(f"â­ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ¸ˆã¿ã‚¹ã‚­ãƒƒãƒ—: {row.è‡ªç¤¾ç®¡ç†ç•ªå·}")
            continue

        # âœ… æ­£è¦åŒ–ï¼‹æ¥é ­è¾é™¤å»ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
        car_name_normalized = unicodedata.normalize("NFKC", str(row.è»Šå)).replace("ãƒ»", "")
        model_code_normalized = unicodedata.normalize("NFKC", str(row.èªå®šå‹å¼))
        model_code_cleaned = re.sub(r"^[A-Z]+-", "", model_code_normalized)
        keyword = f"{car_name_normalized} {model_code_cleaned}"
        print(f"ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ: {keyword}")

        # âœ… éå»ã«åŒã˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æˆåŠŸã—ã¦ã„ãªã„ã‹å±¥æ­´ãƒã‚§ãƒƒã‚¯
        existing_info = ScrapedInfo.query.filter(
            ScrapedInfo.manufacturer_name.notin_(["ä¸æ˜", "ä»®ãƒ¡ãƒ¼ã‚«ãƒ¼"]),
            ScrapedInfo.vehicle.has(
                and_(
                    Vehicle.car_name == row.è»Šå,
                    Vehicle.model_code == row.èªå®šå‹å¼
                )
            )
        ).first()

        if existing_info:
            maker_name = existing_info.manufacturer_name
            print(f"â™»ï¸ æ—¢å­˜ã®ãƒ¡ãƒ¼ã‚«ãƒ¼æƒ…å ±ã‚’å†åˆ©ç”¨: {maker_name}")
        else:
            time.sleep(sleep_seconds)
            maker_name = scrape_manufacturer(row.è»Šå, row.èªå®šå‹å¼)

        if maker_name == "ä¸æ˜":
            fail_count += 1
            fail_ids.append(row.è‡ªç¤¾ç®¡ç†ç•ªå·)
            print(f"âš ï¸ ãƒ¡ãƒ¼ã‚«ãƒ¼å–å¾—å¤±æ•—ï¼ˆ{fail_count}ä»¶ç›®ï¼‰")
            if scraped:
                scraped.manufacturer_name = "ä¸æ˜"
                scraped.retrieved_date = date.today()
                scraped.source_url = "https://www.kurumaerabi.com/"
                print("â™»ï¸ ä»®ãƒ¡ãƒ¼ã‚«ãƒ¼ã‚’ä¸æ˜ã«æ›´æ–°")
            continue
        else:
            success_count += 1
            fail_count = 0

        manufacturer = Manufacturer.query.filter_by(name=maker_name).first()
        if not manufacturer:
            manufacturer = Manufacturer(name=maker_name)
            db.session.add(manufacturer)

        vehicle.manufacturer = manufacturer

        if scraped:
            scraped.manufacturer_name = maker_name
            scraped.model_spec = "å–å¾—äºˆå®š"
            scraped.retrieved_date = date.today()
            scraped.source_url = "https://www.kurumaerabi.com/"
            print(f"â™»ï¸ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æƒ…å ±ã‚’æ›´æ–°: {row.è‡ªç¤¾ç®¡ç†ç•ªå·}")
        else:
            scraped_info = ScrapedInfo(
                vehicle=vehicle,
                manufacturer_name=maker_name,
                model_spec="å–å¾—äºˆå®š",
                retrieved_date=date.today(),
                source_url="https://www.kurumaerabi.com/"
            )
            db.session.add(scraped_info)
            print(f"ğŸ§¾ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æƒ…å ±è¿½åŠ : {row.è‡ªç¤¾ç®¡ç†ç•ªå·}")

        added += 1

    # âœ… CSVã¨ã—ã¦å¤±æ•—IDã‚’å‡ºåŠ›
    if fail_ids:
        with open("failed_ids.csv", mode="w", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(["internal_code"])
            for code in fail_ids:
                writer.writerow([code])
        print(f"ğŸ“„ å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã‚’failed_ids.csvã«æ›¸ãå‡ºã—ã¾ã—ãŸï¼ˆ{len(fail_ids)}ä»¶ï¼‰")

    db.session.commit()
    return jsonify({
        'message': f'{added} ä»¶ã®è»Šä¸¡ã‚’ç™»éŒ²ã—ã¾ã—ãŸ',
        'success_count': success_count,
        'fail_count': len(fail_ids),
        'fail_file': "failed_ids.csv" if fail_ids else None
    })


# âœ… ä¸€è¦§è¡¨ç¤º & ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµã‚Šè¾¼ã¿ãƒ«ãƒ¼ãƒˆ
@bp.route("/vehicles", methods=["GET"])
def list_vehicles():
    keyword = request.args.get("keyword", "").strip()
    query = Vehicle.query

    if keyword:
        query = query.filter(
            or_(
                Vehicle.car_name.ilike(f"%{keyword}%"),
                Vehicle.model_code.ilike(f"%{keyword}%"),
                Vehicle.internal_code.ilike(f"%{keyword}%")
            )
        )

    vehicles = query.order_by(Vehicle.id.desc()).all()
    return render_template("vehicle_list.html", vehicles=vehicles, keyword=keyword)
